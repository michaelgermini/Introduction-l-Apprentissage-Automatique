# Chapitre 13 : Ã‰chantillonnage Monte-Carlo

## ğŸ“š Introduction

Les mÃ©thodes Monte-Carlo permettent d'Ã©chantillonner des distributions complexes et d'approximer des intÃ©grales.

## ğŸ—ºï¸ Carte Mentale : MCMC

```
                    MONTE-CARLO
                          â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                 â”‚                 â”‚
    DIRECT           CHAÃNES DE          AVANCÃ‰
  (IndÃ©pendant)      MARKOV (MCMC)          â”‚
        â”‚                 â”‚                 â”‚
    â”Œâ”€â”€â”€â”´â”€â”€â”€â”         â”Œâ”€â”€â”€â”´â”€â”€â”€â”         â”Œâ”€â”€â”€â”´â”€â”€â”€â”
    â”‚       â”‚         â”‚       â”‚         â”‚       â”‚
 Inverse  Rejet   Metropolis Gibbs     HMC    NUTS
Transform  â”‚      Hastings  Sampling    â”‚       â”‚
    â”‚    Importance    â”‚       â”‚     Hamiltonian
  Box-    Sampling  Accept  Conditionals  Gradient
 Muller              Rate
```

## ğŸ“Š Tableau Comparatif : MÃ©thodes d'Ã‰chantillonnage

| **MÃ©thode** | **Type** | **DÃ©pendance** | **Convergence** | **EfficacitÃ©** | **Usage** |
|------------|---------|---------------|----------------|--------------|-----------|
| **Rejet** | Direct | IndÃ©pendant | ImmÃ©diate | âš ï¸ Faible haute-dim | Simple, 1D-2D |
| **Metropolis-Hastings** | MCMC | ChaÃ®ne | Asymptotique | âœ“ Moyenne | Standard |
| **Gibbs** | MCMC | ChaÃ®ne | Asymptotique | âœ“âœ“ Bonne | Conditionnelles simples |
| **HMC** | MCMC | ChaÃ®ne | Rapide | âœ“âœ“âœ“ Excellente | Gradients disponibles |
| **NUTS** | MCMC | ChaÃ®ne | TrÃ¨s rapide | âœ“âœ“âœ“ Excellente | Stan, PyMC |

## ğŸ“ Visualisation : MCMC en Action

```
Distribution Cible p(x) :         Ã‰chantillonnage MCMC :

     p(x)                          Trajectoire MCMC
      â”‚                               
  1.0 â”‚   â•±â”€â•²                     â—â”€â”€â†’â—â”€â”€â†’â—
      â”‚  â•±   â•²                   â•±      â†“
  0.5 â”‚ â•±     â•²                 â—       â—
      â”‚â•±       â•²___             â†“       â†“
  0   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ x        â—â†â”€â”€â—â†â”€â”€â—
     -3  -1  1  3             
                              Burn-in Phase (1000 iter)
                              Sampling Phase (5000 iter)

Histogramme des Ã©chantillons :   AutocorrÃ©lation :

     â•±â•²                           ACF
    â•±  â•²                           1â”‚â—
   â•±    â•²                           â”‚  â—
  â•±      â•²___                       â”‚    â—  â—
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’                     â”‚      â—   â—
Converge vers p(x) !                0â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ Lag
```

---

## 13.1 Principes GÃ©nÃ©raux

### Approximation Monte-Carlo

Pour estimer ğ”¼_P[f(X)] :
```
ğ”¼[f] â‰ˆ (1/n) Î£áµ¢ f(xáµ¢)  oÃ¹ xáµ¢ ~ P
```

**Loi des grands nombres** : Convergence vers ğ”¼[f]

---

## 13.2 Ã‰chantillonnage par Rejet

**Algorithme** :
1. Ã‰chantillonner x ~ q
2. Accepter avec probabilitÃ© p(x)/(MÂ·q(x))

```python
def rejection_sampling(target, proposal, M, n_samples):
    samples = []
    while len(samples) < n_samples:
        x = proposal.rvs()
        u = np.random.uniform()
        if u < target(x) / (M * proposal.pdf(x)):
            samples.append(x)
    return np.array(samples)
```

---

## 13.3 ChaÃ®nes de Markov

### 13.3.1 DÃ©finitions

Une **chaÃ®ne de Markov** {X_t} satisfait :
```
P(X_{t+1}|X_t, X_{t-1}, ..., X_0) = P(X_{t+1}|X_t)
```

### 13.3.2 Distribution Stationnaire

Ï€ est **stationnaire** si :
```
Ï€(x') = Î£_x Ï€(x) P(x â†’ x')
```

### 13.3.3 ErgodicitÃ©

**ThÃ©orÃ¨me** : Si la chaÃ®ne est irrÃ©ductible et apÃ©riodique :
```
lim_{tâ†’âˆ} P^t(x, Â·) = Ï€
```

---

## 13.4 Gibbs Sampling

**Principe** : Ã‰chantillonner chaque variable conditionnellement aux autres.

```python
def gibbs_sampling(n_iter, x_init):
    x = x_init.copy()
    samples = [x.copy()]
    
    for _ in range(n_iter):
        # Ã‰chantillonner X1 | X2, X3, ...
        x[0] = sample_x1_given_others(x)
        
        # Ã‰chantillonner X2 | X1, X3, ...
        x[1] = sample_x2_given_others(x)
        
        # ...
        
        samples.append(x.copy())
    
    return np.array(samples)
```

---

## 13.5 Metropolis-Hastings

**Algorithme** :
1. Proposer x' ~ q(Â·|x)
2. Accepter avec probabilitÃ© :
```
Î± = min(1, (p(x')q(x|x')) / (p(x)q(x'|x)))
```

```python
def metropolis_hastings(target, proposal, x0, n_iter):
    x = x0
    samples = [x]
    
    for _ in range(n_iter):
        # Proposition
        x_prop = proposal(x)
        
        # Taux d'acceptation
        alpha = min(1, target(x_prop) / target(x))
        
        # Acceptation/rejet
        if np.random.uniform() < alpha:
            x = x_prop
        
        samples.append(x)
    
    return np.array(samples)
```

---

[â¬…ï¸ Chapitre prÃ©cÃ©dent](./chapitre-12-comparaison-distributions.md) | [Retour](../README.md) | [Suite â¡ï¸](./chapitre-14-champs-markov.md)

