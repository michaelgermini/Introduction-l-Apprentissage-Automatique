# Chapitre 19 : MÃ©thodes GÃ©nÃ©ratives Profondes

## ğŸ“š Introduction

Ce chapitre prÃ©sente les techniques modernes de modÃ©lisation gÃ©nÃ©rative basÃ©es sur les rÃ©seaux de neurones profonds.

## ğŸ—ºï¸ Carte Mentale : ModÃ¨les GÃ©nÃ©ratifs

```
                    GÃ‰NÃ‰RATION DE DONNÃ‰ES
                            â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                   â”‚                   â”‚
    EXPLICITE          IMPLICITE           HYBRIDE
   (DensitÃ© p(x))    (Ã‰chantillonnage)        â”‚
        â”‚                   â”‚                   â”‚
    â”Œâ”€â”€â”€â”´â”€â”€â”€â”           â”Œâ”€â”€â”€â”´â”€â”€â”€â”         Diffusion
    â”‚       â”‚           â”‚       â”‚          Models
  VAE   Flows        GAN    Score           â”‚
    â”‚       â”‚           â”‚    Matching    Stable
 ELBO  Invertible  Adversarial  â”‚       Diffusion
  KL   Bijection   Min-Max    Langevin   DALL-E 2
```

## ğŸ“Š Tableau Comparatif : MÃ©thodes GÃ©nÃ©ratives

| **MÃ©thode** | **Type** | **DensitÃ© p(x)** | **QualitÃ©** | **DiversitÃ©** | **StabilitÃ©** | **ComplexitÃ©** |
|------------|---------|-----------------|------------|--------------|--------------|---------------|
| **VAE** | Explicite | âœ“ Oui (approx.) | âš ï¸ Moyenne | âœ“âœ“ Bonne | âœ“âœ“ Stable | â­â­ Moyenne |
| **GAN** | Implicite | âœ— Non | âœ“âœ“âœ“ Excellente | âš ï¸ Mode collapse | âš ï¸ Instable | â­â­â­ Ã‰levÃ©e |
| **Normalizing Flows** | Explicite | âœ“ Oui (exacte) | âœ“ Bonne | âœ“âœ“ Bonne | âœ“âœ“ Stable | â­â­â­ Ã‰levÃ©e |
| **Diffusion** | Hybride | âœ“ Oui (implicite) | âœ“âœ“âœ“ Excellente | âœ“âœ“âœ“ Excellente | âœ“âœ“ Stable | â­â­â­â­ TrÃ¨s Ã©levÃ©e |

## ğŸ¨ Comparaison Visuelle : VAE vs GAN

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    VAE (Variational Autoencoder)             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    Image x          Encodeur         z (latent)      DÃ©codeur        xÌ‚ (reconstruit)
    â”Œâ”€â”€â”€â”€â”€â”           â†“                 â†“               â†“              â”Œâ”€â”€â”€â”€â”€â”
    â”‚ ğŸ±  â”‚  â”€â”€â”€â”€â”€â†’  Î¼(x), Ïƒ(x)  â†’  Sampling  â†’  GÃ©nÃ©ration  â”€â”€â”€â”€â”€â†’  â”‚ ğŸ±  â”‚
    â””â”€â”€â”€â”€â”€â”˜                          z~N(Î¼,ÏƒÂ²)                        â””â”€â”€â”€â”€â”€â”˜

  Objectif : Maximiser ELBO = ğ”¼[log p(x|z)] - KL(q(z|x)||p(z))
             â†“                     â†“
       Reconstruction      RÃ©gularisation
       (qualitÃ©)          (distribution smooth)

Avantages : âœ“ Stable, âœ“ DensitÃ© explicite, âœ“ Interpolation
InconvÃ©nients : Images un peu floues


â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    GAN (Generative Adversarial Network)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    Bruit z          GÃ©nÃ©rateur        Image fake       Discriminateur
    â”Œâ”€â”€â”€â”€â”€â”             G                â”Œâ”€â”€â”€â”€â”€â”             D
    â”‚ âˆ¼âˆ¼âˆ¼ â”‚  â”€â”€â”€â”€â”€â†’  RÃ©seau   â”€â”€â”€â”€â”€â†’   â”‚ ğŸ±? â”‚  â”€â”€â”€â”€â”€â†’   Real/Fake?
    â””â”€â”€â”€â”€â”€â”˜          Neuronal           â””â”€â”€â”€â”€â”€â”˜           [0...1]
                                            â†‘
                        Image rÃ©elle        â”‚
                        â”Œâ”€â”€â”€â”€â”€â”             â”‚
                        â”‚ ğŸ±  â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â””â”€â”€â”€â”€â”€â”˜

  Objectif : min_G max_D  ğ”¼[log D(x)] + ğ”¼[log(1-D(G(z)))]
             â†‘           â†‘
         Tromper D   Distinguer

Avantages : âœ“âœ“âœ“ Images nettes, âœ“ Haute qualitÃ©
InconvÃ©nients : âœ— Instable, âœ— Mode collapse
```

---

## 19.1 Flots Normalisants (Normalizing Flows)

### Principe

Transformer une distribution simple z ~ N(0, I) en distribution complexe x = f(z).

**Changement de variable** :
```
p_x(x) = p_z(fâ»Â¹(x)) |det âˆ‚fâ»Â¹/âˆ‚x|
```

**Architectures** : RealNVP, Glow, MAF

---

## 19.2 Autoencodeurs Variationnels (VAE)

### Architecture

**Encodeur** : q(z|x) = N(Î¼(x), Î£(x))
**DÃ©codeur** : p(x|z)

### Fonction Objectif

**ELBO** :
```
â„’ = ğ”¼_q[log p(x|z)] - KL(q(z|x) || p(z))
```

```python
class VAE(nn.Module):
    def __init__(self, input_dim, latent_dim):
        super().__init__()
        # Encodeur
        self.fc1 = nn.Linear(input_dim, 400)
        self.fc_mu = nn.Linear(400, latent_dim)
        self.fc_logvar = nn.Linear(400, latent_dim)
        
        # DÃ©codeur
        self.fc3 = nn.Linear(latent_dim, 400)
        self.fc4 = nn.Linear(400, input_dim)
    
    def encode(self, x):
        h = F.relu(self.fc1(x))
        return self.fc_mu(h), self.fc_logvar(h)
    
    def reparameterize(self, mu, logvar):
        std = torch.exp(0.5 * logvar)
        eps = torch.randn_like(std)
        return mu + eps * std
    
    def decode(self, z):
        h = F.relu(self.fc3(z))
        return torch.sigmoid(self.fc4(h))
    
    def forward(self, x):
        mu, logvar = self.encode(x)
        z = self.reparameterize(mu, logvar)
        return self.decode(z), mu, logvar
```

---

## 19.3 GANs (Generative Adversarial Networks)

### Principe

**Deux rÃ©seaux** :
- GÃ©nÃ©rateur G : z â†’ x
- Discriminateur D : x â†’ [0, 1]

### Objectif Min-Max

```
min_G max_D ğ”¼_x[log D(x)] + ğ”¼_z[log(1 - D(G(z)))]
```

```python
class Generator(nn.Module):
    def __init__(self, latent_dim, img_shape):
        super().__init__()
        self.model = nn.Sequential(
            nn.Linear(latent_dim, 128),
            nn.ReLU(),
            nn.Linear(128, 256),
            nn.ReLU(),
            nn.Linear(256, np.prod(img_shape)),
            nn.Tanh()
        )
    
    def forward(self, z):
        return self.model(z)

class Discriminator(nn.Module):
    def __init__(self, img_shape):
        super().__init__()
        self.model = nn.Sequential(
            nn.Linear(np.prod(img_shape), 256),
            nn.LeakyReLU(0.2),
            nn.Linear(256, 128),
            nn.LeakyReLU(0.2),
            nn.Linear(128, 1),
            nn.Sigmoid()
        )
    
    def forward(self, img):
        return self.model(img)

# EntraÃ®nement
for epoch in range(n_epochs):
    for real_imgs in dataloader:
        # EntraÃ®ner discriminateur
        z = torch.randn(batch_size, latent_dim)
        fake_imgs = generator(z)
        
        d_loss = -torch.mean(torch.log(discriminator(real_imgs)) + 
                             torch.log(1 - discriminator(fake_imgs)))
        
        # EntraÃ®ner gÃ©nÃ©rateur
        g_loss = -torch.mean(torch.log(discriminator(generator(z))))
```

### Variantes

**DCGAN** : Convolutions
**WGAN** : Wasserstein distance
**StyleGAN** : Style transfer

---

## 19.4 ModÃ¨les de Diffusion

### Principe

**Forward** : Ajouter progressivement du bruit
**Reverse** : Apprendre Ã  dÃ©bruiter

**Score matching** : Apprendre âˆ‡_x log p(x)

---

[â¬…ï¸ Partie 4](../partie-4-modeles-probabilistes/chapitre-18-apprentissage-graphiques.md) | [Retour](../README.md) | [Suite â¡ï¸](../partie-6-non-supervise/chapitre-20-clustering.md)

