# Chapitre 3 : Introduction Ã  l'Optimisation

## ğŸ“š Introduction

L'optimisation est au cÅ“ur du machine learning. EntraÃ®ner un modÃ¨le revient Ã  rÃ©soudre un problÃ¨me d'optimisation : trouver les paramÃ¨tres qui minimisent une fonction de coÃ»t. Ce chapitre couvre les algorithmes d'optimisation essentiels utilisÃ©s en ML.

## ğŸ—ºï¸ Carte Mentale : MÃ©thodes d'Optimisation

```
                        OPTIMISATION EN ML
                               â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚                  â”‚                  â”‚
      SANS CONTRAINTE    AVEC CONTRAINTES    STOCHASTIQUE
            â”‚                  â”‚                  â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”´â”€â”€â”€â”          â”Œâ”€â”€â”€â”´â”€â”€â”€â”
    â”‚               â”‚      â”‚       â”‚          â”‚       â”‚
 Gradient    Newton &  Lagrange KKT         SGD    ADAM
  Descent    Quasi-N.    â”‚                   â”‚
    â”‚           â”‚     PÃ©nalitÃ©           Mini-batch
 Line Search  BFGS   AugmentÃ©e
```

## ğŸ“Š Tableau Comparatif des Algorithmes

| **Algorithme** | **ComplexitÃ©/iter** | **Convergence** | **Usage ML** | **Avantages** | **InconvÃ©nients** |
|----------------|-------------------|----------------|-------------|--------------|------------------|
| **Gradient Descent** | O(n) | LinÃ©aire | Universel | Simple | Lent |
| **Newton** | O(nÂ³) | Quadratique | Petit n | Rapide | CoÃ»t Ã©levÃ© |
| **SGD** | O(1) | Sous-linÃ©aire | Big Data | Scalable | Bruyant |
| **ADAM** | O(1) | Adaptatif | Deep Learning | Robuste | HyperparamÃ¨tres |
| **L-BFGS** | O(nÃ—m) | SuperlinÃ©aire | ML classique | Efficace | MÃ©moire |

## ğŸ¯ Diagramme de Flux : Choix d'Algorithme

```
         DÃ©but : ProblÃ¨me d'optimisation
                      â”‚
                      â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ Dataset de taille N ?   â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚              â”‚
           N < 10â´        N > 10â¶
              â”‚              â”‚
              â–¼              â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ Newton  â”‚    â”‚   SGD   â”‚
         â”‚ L-BFGS  â”‚    â”‚  ADAM   â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚              â”‚
              â–¼              â–¼
       Convergence       Mini-batch
         rapide           adaptatif
```

---

## 3.1 Terminologie de Base

### ProblÃ¨me d'Optimisation

Un problÃ¨me d'optimisation gÃ©nÃ©ral s'Ã©crit :

```
minimize    f(x)
subject to  x âˆˆ C
```

oÃ¹ :
- **f : â„â¿ â†’ â„** est la fonction objectif (fonction de coÃ»t)
- **C âŠ‚ â„â¿** est l'ensemble des contraintes
- **x âˆˆ â„â¿** est la variable d'optimisation

### DÃ©finitions

**Minimum global** : x* est un minimum global si f(x*) â‰¤ f(x) pour tout x âˆˆ C

**Minimum local** : x* est un minimum local s'il existe Îµ > 0 tel que f(x*) â‰¤ f(x) pour tout x âˆˆ C âˆ© B(x*, Îµ)

**Point stationnaire** : x tel que âˆ‡f(x) = 0

---

## 3.2 Optimisation Sans Contrainte

### 3.2.1 Conditions d'OptimalitÃ©

#### Condition NÃ©cessaire du Premier Ordre

Si x* est un minimum local de f diffÃ©rentiable, alors :
```
âˆ‡f(x*) = 0
```

#### Condition NÃ©cessaire du Second Ordre

Si x* est un minimum local de f deux fois diffÃ©rentiable, alors :
```
âˆ‡f(x*) = 0  et  Hf(x*) âª° 0
```

#### Condition Suffisante du Second Ordre

Si âˆ‡f(x*) = 0 et Hf(x*) â‰» 0, alors x* est un minimum local strict.

**Exemple** : Pour f(x) = xÂ² - 2x + 1
```
âˆ‡f(x) = 2x - 2 = 0  âŸ¹  x* = 1
H f(x) = 2 > 0  âŸ¹  x* est un minimum global
```

### 3.2.2 Ensembles et Fonctions Convexes

#### Ensemble Convexe

Un ensemble C est **convexe** si pour tous x, y âˆˆ C et Î¸ âˆˆ [0,1] :
```
Î¸x + (1-Î¸)y âˆˆ C
```

**Exemples** :
- â„â¿ est convexe
- {x : Ax â‰¤ b} est convexe (demi-espaces)
- Boules : {x : â€–x - xâ‚€â€– â‰¤ r} est convexe

#### Fonction Convexe

Une fonction f est **convexe** si pour tous x, y et Î¸ âˆˆ [0,1] :
```
f(Î¸x + (1-Î¸)y) â‰¤ Î¸f(x) + (1-Î¸)f(y)
```

**PropriÃ©tÃ© fondamentale** : Pour f convexe diffÃ©rentiable :
```
f(y) â‰¥ f(x) + âˆ‡f(x)áµ€(y - x)  pour tous x, y
```

**Test de convexitÃ©** : f est convexe âŸº Hf(x) âª° 0 pour tout x

**Exemples de fonctions convexes** :
- f(x) = xáµ€Ax avec A âª° 0
- f(x) = â€–xâ€–
- f(x) = exp(x)
- f(x) = -log(x) pour x > 0

### 3.2.3 IntÃ©rieur Relatif

L'**intÃ©rieur relatif** de C, notÃ© ri(C), est l'intÃ©rieur de C dans son affine hull.

**Importance** : Les conditions d'optimalitÃ© pour les fonctions convexes s'appliquent sur ri(dom f).

### 3.2.4 DÃ©rivÃ©es de Fonctions Convexes et Conditions d'OptimalitÃ©

#### ThÃ©orÃ¨me Fondamental

Pour f convexe diffÃ©rentiable, x* est un minimum global si et seulement si :
```
âˆ‡f(x*) = 0
```

**ConsÃ©quence** : Pour les fonctions convexes, tout minimum local est global !

### 3.2.5 Direction de Descente et Descente la Plus Rapide

#### Direction de Descente

Un vecteur d est une **direction de descente** en x si :
```
âˆ‡f(x)áµ€d < 0
```

La **direction de descente la plus rapide** est :
```
d = -âˆ‡f(x) / â€–âˆ‡f(x)â€–
```

### 3.2.6 Descente de Gradient

**Algorithme de descente de gradient** :
```
x_{k+1} = x_k - Î±_k âˆ‡f(x_k)
```

oÃ¹ Î±_k > 0 est le pas d'apprentissage (learning rate).

#### ğŸ“ Intuition GÃ©omÃ©trique

```
Paysage de la fonction f(x) :

    f(x)
     â†‘
     â”‚     â•±â•²              Descente de gradient :
     â”‚    â•±  â•²             On suit la pente nÃ©gative
     â”‚   â•±    â•²    
     â”‚  â•±  xâ‚€  â•²          xâ‚€ â”€â”€â”€â”€â”€â”€â†’ xâ‚ â”€â”€â”€â”€â”€â”€â†’ xâ‚‚ â”€â”€â†’ x*
     â”‚ â•±   â†“    â•²         (gradient nÃ©gatif Ã  chaque Ã©tape)
     â”‚â•±    xâ‚    â•²        
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ x
          â†“
         xâ‚‚â†’x*
```

#### ğŸ“ Exemple Complet Pas Ã  Pas

**ProblÃ¨me** : Minimiser f(x, y) = xÂ² + 4yÂ²

```
DONNÃ‰ES INITIALES :
    f(x, y) = xÂ² + 4yÂ²
    Point initial : (xâ‚€, yâ‚€) = (4, 2)
    Pas d'apprentissage : Î± = 0.1

Ã‰TAPE 0 : Calcul du gradient
    âˆ‡f(x, y) = [âˆ‚f/âˆ‚x, âˆ‚f/âˆ‚y]áµ€ = [2x, 8y]áµ€

    Au point (4, 2) :
        âˆ‡f(4, 2) = [2Ã—4, 8Ã—2]áµ€ = [8, 16]áµ€
        f(4, 2) = 16 + 16 = 32

ITÃ‰RATION 1 :
    xâ‚ = xâ‚€ - Î±Â·âˆ‡f_x(xâ‚€)
       = 4 - 0.1 Ã— 8
       = 4 - 0.8 = 3.2
    
    yâ‚ = yâ‚€ - Î±Â·âˆ‡f_y(yâ‚€)
       = 2 - 0.1 Ã— 16
       = 2 - 1.6 = 0.4
    
    Point : (xâ‚, yâ‚) = (3.2, 0.4)
    f(3.2, 0.4) = 10.24 + 0.64 = 10.88
    RÃ©duction : 32 â†’ 10.88 âœ“

ITÃ‰RATION 2 :
    âˆ‡f(3.2, 0.4) = [6.4, 3.2]áµ€
    
    xâ‚‚ = 3.2 - 0.1 Ã— 6.4 = 2.56
    yâ‚‚ = 0.4 - 0.1 Ã— 3.2 = 0.08
    
    f(2.56, 0.08) = 6.554 + 0.026 = 6.58
    RÃ©duction : 10.88 â†’ 6.58 âœ“

ITÃ‰RATION 3 :
    âˆ‡f(2.56, 0.08) = [5.12, 0.64]áµ€
    
    xâ‚ƒ = 2.56 - 0.1 Ã— 5.12 = 2.048
    yâ‚ƒ = 0.08 - 0.1 Ã— 0.64 = 0.016
    
    f(2.048, 0.016) â‰ˆ 4.19
    RÃ©duction : 6.58 â†’ 4.19 âœ“

CONVERGENCE :
    AprÃ¨s plusieurs itÃ©rations â†’ (x*, y*) = (0, 0)
    Minimum : f(0, 0) = 0

SchÃ©ma de convergence :
    
    y
    â”‚  â—(4,2)          Courbes de niveau de f
    â”‚   â•²              (ellipses)
    â”‚    â—(3.2,0.4)
  1 â”‚      â•²           Trajectoire de descente
    â”‚       â—(2.56,0.08)
    â”‚         â•²
  0 â”‚          â—â”€â”€â”€â”€â”€â—(0,0) â˜…
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ x
    0         2          4
```

#### âš™ï¸ Choix du Pas d'Apprentissage Î±

| **Î±** | **Effet** | **Convergence** | **Recommandation** |
|-------|----------|----------------|-------------------|
| Trop grand (Î± > 2/L) | Divergence | âœ— Aucune | Ã‰viter |
| Grand (Î± â‰ˆ 1/L) | Oscillations | âš ï¸ Lente | Attention |
| Optimal (Î± = Î¼/LÂ²) | Stable | âœ“ Rapide | IdÃ©al |
| Petit (Î± << 1/L) | TrÃ¨s lent | âœ“ Garantie | SÃ»r mais lent |

**Illustration** :

```
Î± trop grand :                Î± optimal :              Î± trop petit :
    â•±â•²                           â•±â•²                        â•±â•²
   â•±  â•²                         â•±  â•²                      â•±  â•²
  â—â”€â”€â”€â”€â—                       â—â”€â†’â—â”€â†’â—                   â—â”€â†’â”€â†’â”€â†’â”€â†’â—
 â—      â—                        â†“  â†“                     (trÃ¨s lent)
â—        â— Diverge !             â˜… Converge
```

**ImplÃ©mentation Python ComplÃ¨te** :
```python
def gradient_descent(f, grad_f, x0, alpha=0.01, max_iter=1000, tol=1e-6):
    """
    Descente de gradient
    
    Args:
        f: fonction objectif
        grad_f: gradient de f
        x0: point initial
        alpha: pas d'apprentissage
        max_iter: nombre maximal d'itÃ©rations
        tol: tolÃ©rance pour la convergence
    """
    x = x0.copy()
    history = [x.copy()]
    
    for k in range(max_iter):
        grad = grad_f(x)
        
        # Test de convergence
        if np.linalg.norm(grad) < tol:
            print(f"Convergence Ã  l'itÃ©ration {k}")
            break
        
        # Mise Ã  jour
        x = x - alpha * grad
        history.append(x.copy())
    
    return x, np.array(history)

# Exemple : minimiser f(x) = x^T A x - b^T x
A = np.array([[4, 1], [1, 3]])
b = np.array([1, 2])

f = lambda x: 0.5 * x @ A @ x - b @ x
grad_f = lambda x: A @ x - b

x0 = np.array([0.0, 0.0])
x_opt, history = gradient_descent(f, grad_f, x0, alpha=0.1)
```

#### ThÃ©orÃ¨me de Convergence

Pour f fortement convexe avec L-Lipschitz gradient :
```
f(x_k) - f(x*) â‰¤ (1 - Î¼/L)^k (f(x_0) - f(x*))
```

oÃ¹ Î¼ est le paramÃ¨tre de convexitÃ© forte.

**Taux de convergence** : LinÃ©aire (exponentiel en nombre d'itÃ©rations)

### 3.2.7 Recherche LinÃ©aire (Line Search)

Au lieu de fixer Î±, on peut le choisir Ã  chaque itÃ©ration :

#### RÃ¨gle d'Armijo (Backtracking)

```python
def backtracking_line_search(f, x, d, grad, alpha=1.0, beta=0.5, sigma=0.1):
    """
    Recherche linÃ©aire avec backtracking
    """
    while f(x + alpha * d) > f(x) + sigma * alpha * grad @ d:
        alpha *= beta
    return alpha
```

#### Recherche Exacte

Minimiser f(x + Î±d) par rapport Ã  Î± :
```
Î±* = argmin_Î± f(x + Î±d)
```

---

## 3.3 Descente de Gradient Stochastique

### 3.3.1 MÃ©thodes d'Approximation Stochastique

En ML, on minimise souvent :
```
f(Î¸) = ğ”¼[â„“(Î¸; Z)] = (1/n) Î£áµ¢ â„“(Î¸; záµ¢)
```

**ProblÃ¨me** : Calculer âˆ‡f(Î¸) nÃ©cessite n Ã©valuations.

**Solution** : Approximer le gradient par un Ã©chantillon :
```
âˆ‡f(Î¸) â‰ˆ âˆ‡â„“(Î¸; z_i)  oÃ¹ i est choisi alÃ©atoirement
```

## ğŸ“Š Comparaison Visuelle : GD vs SGD vs ADAM

### Trajectoires de Convergence

```
Paysage d'optimisation (vue de dessus) :

         Gradient Descent (GD)          
              â•­â”€â”€â”€â”€â”€â”€â”€â•®                 
             â•±         â•²                
        xâ‚€ â—â”€â”€â”€â”€â†’â—â”€â”€â”€â”€â†’â— x*            Lisse, dÃ©terministe
           â•²         â•±                 Convergence monotone
            â•°â”€â”€â”€â”€â”€â”€â”€â•¯                  

         Stochastic GD (SGD)           
              â•­â”€â”€â”€â”€â”€â”€â”€â•®                 
             â•±    â—â†—   â•²               Bruyant, stochastique
        xâ‚€ â—â†’â—â†˜â†’â—â†—â†’â—â†’â— x*             Oscille autour de x*
           â•²    â—â†˜   â•±                Convergence en moyenne
            â•°â”€â”€â”€â”€â”€â”€â”€â•¯                  

              ADAM                     
              â•­â”€â”€â”€â”€â”€â”€â”€â•®                 
             â•±         â•²               Adaptatif
        xâ‚€ â—â”€â”€â†’â—â”€â”€â†’â—â”€â”€â†’â— x*           Convergence rapide
           â•²         â•±                 Peu d'oscillations
            â•°â”€â”€â”€â”€â”€â”€â”€â•¯                  
```

### ğŸ“ˆ Courbes de Convergence

```
    Loss
     â”‚
 10â´ â”‚â—                        
     â”‚ â•²             â”€â”€â”€â”€ GD
     â”‚  â•²â”€â”€â”€â”€â”€â”€â”€     â”€â”€â”€â”€ SGD (bruyant)
 10Â² â”‚   â•²  â•² /â•²    â”€â”€â”€â”€ ADAM
     â”‚    â•²  â•²/  â•²  
 10â° â”‚     â”€â”€â”€â”€â”€â”€â”€â”€â—
     â”‚          SGD
 10â»Â² â”‚           â”€â”€â”€â”€â”€ADAM
     â”‚               â”€â”€â”€â”€GD
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ Iterations
       0   50  100  150  200
```

### ğŸ“‹ Tableau Comparatif DÃ©taillÃ©

| **CritÃ¨re** | **GD** | **SGD** | **Mini-Batch SGD** | **Momentum** | **ADAM** |
|-------------|--------|---------|-------------------|-------------|----------|
| **Gradient par iter** | Full (N samples) | 1 sample | B samples | B samples | B samples |
| **ComplexitÃ©/iter** | O(N) | O(1) | O(B) | O(B) | O(B) |
| **Convergence** | Monotone | BruitÃ©e | Stable | Rapide | TrÃ¨s rapide |
| **MÃ©moire** | O(d) | O(d) | O(d) | O(2d) | O(3d) |
| **HyperparamÃ¨tres** | Î± | Î±, schedule | Î±, B | Î±, Î² | Î±, Î²â‚, Î²â‚‚ |
| **ScalabilitÃ©** | âœ— Mauvaise | âœ“âœ“ Excellente | âœ“âœ“ Excellente | âœ“âœ“ Excellente | âœ“âœ“ Excellente |
| **Robustesse** | âš ï¸ Moyenne | âš ï¸ Sensible | âœ“ Bonne | âœ“ Bonne | âœ“âœ“ TrÃ¨s bonne |
| **Usage ML** | Petit N | Big Data | Universel | Computer Vision | Deep Learning |

### âš™ï¸ Formules CÃ´te Ã  CÃ´te

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  GRADIENT DESCENT (GD)                                           â”‚
â”‚  Î¸â‚–â‚Šâ‚ = Î¸â‚– - Î± âˆ‡f(Î¸â‚–)                                           â”‚
â”‚  â†ª Utilise toutes les donnÃ©es                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STOCHASTIC GD (SGD)                                             â”‚
â”‚  Î¸â‚–â‚Šâ‚ = Î¸â‚– - Î± âˆ‡â„“(Î¸â‚–; záµ¢)                                       â”‚
â”‚  â†ª Utilise 1 Ã©chantillon alÃ©atoire                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  MINI-BATCH SGD                                                  â”‚
â”‚  Î¸â‚–â‚Šâ‚ = Î¸â‚– - Î± (1/B) Î£áµ¢âˆˆBatch âˆ‡â„“(Î¸â‚–; záµ¢)                       â”‚
â”‚  â†ª Compromis entre GD et SGD                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  MOMENTUM                                                        â”‚
â”‚  vâ‚– = Î² vâ‚–â‚‹â‚ + gâ‚–                                               â”‚
â”‚  Î¸â‚–â‚Šâ‚ = Î¸â‚– - Î± vâ‚–                                               â”‚
â”‚  â†ª Accumule la vitesse (inertie)                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ADAM (Adaptive Moment Estimation)                               â”‚
â”‚  mâ‚– = Î²â‚ mâ‚–â‚‹â‚ + (1-Î²â‚) gâ‚–        (1er moment : moyenne)         â”‚
â”‚  vâ‚– = Î²â‚‚ vâ‚–â‚‹â‚ + (1-Î²â‚‚) gâ‚–Â²       (2Ã¨me moment : variance)       â”‚
â”‚  Î¸â‚–â‚Šâ‚ = Î¸â‚– - Î± mÌ‚â‚– / (âˆšvÌ‚â‚– + Îµ)                                  â”‚
â”‚  â†ª Adapte le pas pour chaque paramÃ¨tre                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ¯ Guide de Choix

```
                Quel algorithme choisir ?
                         â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                                  â”‚
    N < 10,000                        N > 1,000,000
    Dataset petit                     Big Data
        â”‚                                  â”‚
    â”Œâ”€â”€â”€â”´â”€â”€â”€â”                          â”Œâ”€â”€â”€â”´â”€â”€â”€â”
    â”‚       â”‚                          â”‚       â”‚
  Convexe Non-convexe              Batch Size ?
    â”‚       â”‚                          â”‚
   GD    L-BFGS                  â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”
         Newton                  â”‚           â”‚
                              B=1          B>1
                               â”‚            â”‚
                             SGD      Mini-batch SGD
                                           â”‚
                                      Deep Learning ?
                                           â”‚
                                      â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”
                                      â”‚         â”‚
                                    Oui       Non
                                      â”‚         â”‚
                                   ADAM    Momentum
                                            SGD
```

### ğŸ’¡ Conseils Pratiques

**Taille de Batch RecommandÃ©e** :

| **Cas** | **Batch Size** | **Raison** |
|---------|---------------|-----------|
| Petits modÃ¨les | 32-64 | Ã‰quilibre vitesse/stabilitÃ© |
| CNN (images) | 64-256 | ParallÃ©lisation GPU |
| Transformers (NLP) | 16-32 | Contrainte mÃ©moire |
| TrÃ¨s grands modÃ¨les | 8-16 | Limite GPU |

**Learning Rate** :

| **Algorithme** | **Î± initial** | **Schedule** |
|---------------|--------------|-------------|
| GD | 0.01-0.1 | Constant ou decay |
| SGD | 0.01-0.1 | 1/âˆšt ou cosine |
| Momentum | 0.01 | Step decay |
| ADAM | 0.001 | Constant ou warmup |

### 3.3.2 Algorithme SGD

```
Î¸_{k+1} = Î¸_k - Î±_k âˆ‡â„“(Î¸_k; z_{i_k})
```

**ImplÃ©mentation** :
```python
def sgd(data, loss_grad, theta0, epochs=10, batch_size=32, alpha=0.01):
    """
    Descente de gradient stochastique
    """
    theta = theta0.copy()
    n = len(data)
    
    for epoch in range(epochs):
        # MÃ©langer les donnÃ©es
        np.random.shuffle(data)
        
        for i in range(0, n, batch_size):
            batch = data[i:i+batch_size]
            
            # Gradient sur le mini-batch
            grad = sum(loss_grad(theta, x) for x in batch) / len(batch)
            
            # Mise Ã  jour
            theta -= alpha * grad
        
        print(f"Epoch {epoch+1}/{epochs}")
    
    return theta
```

#### Choix du Pas d'Apprentissage

Conditions de Robbins-Monro pour la convergence :
```
Î£ Î±_k = âˆ  et  Î£ Î±_kÂ² < âˆ
```

**Exemples** :
- Î±_k = Î±â‚€ / (1 + k)
- Î±_k = Î±â‚€ / âˆšk
- Learning rate schedule : rÃ©duction par paliers

### 3.3.3 L'Algorithme ADAM

**ADAM** (Adaptive Moment Estimation) combine :
- Momentum : moyenne mobile des gradients
- RMSprop : moyenne mobile des gradients au carrÃ©

**Algorithme** :
```
m_k = Î²â‚ m_{k-1} + (1-Î²â‚) g_k
v_k = Î²â‚‚ v_{k-1} + (1-Î²â‚‚) g_kÂ²

mÌ‚_k = m_k / (1 - Î²â‚^k)
vÌ‚_k = v_k / (1 - Î²â‚‚^k)

Î¸_{k+1} = Î¸_k - Î± mÌ‚_k / (âˆšvÌ‚_k + Îµ)
```

**ParamÃ¨tres standards** :
- Î²â‚ = 0.9
- Î²â‚‚ = 0.999
- Îµ = 10â»â¸

**ImplÃ©mentation** :
```python
def adam(data, loss_grad, theta0, epochs=10, alpha=0.001, 
         beta1=0.9, beta2=0.999, eps=1e-8):
    """
    Optimiseur ADAM
    """
    theta = theta0.copy()
    m = np.zeros_like(theta)
    v = np.zeros_like(theta)
    t = 0
    
    for epoch in range(epochs):
        for x in data:
            t += 1
            grad = loss_grad(theta, x)
            
            # Mise Ã  jour des moments
            m = beta1 * m + (1 - beta1) * grad
            v = beta2 * v + (1 - beta2) * grad**2
            
            # Correction du biais
            m_hat = m / (1 - beta1**t)
            v_hat = v / (1 - beta2**t)
            
            # Mise Ã  jour des paramÃ¨tres
            theta -= alpha * m_hat / (np.sqrt(v_hat) + eps)
    
    return theta
```

---

## 3.4 Optimisation Contrainte

### 3.4.1 Multiplicateurs de Lagrange

Pour minimiser f(x) sous contrainte h(x) = 0 :

**Lagrangien** :
```
â„’(x, Î») = f(x) + Î»áµ€h(x)
```

**Conditions KKT** (Karush-Kuhn-Tucker) :
```
âˆ‡_x â„’(x*, Î»*) = 0
h(x*) = 0
```

**Exemple** : Minimiser f(x, y) = xÂ² + yÂ² sous contrainte x + y = 1

```python
# Lagrangien: L = xÂ² + yÂ² + Î»(x + y - 1)
# âˆ‡L = 0  âŸ¹  2x + Î» = 0, 2y + Î» = 0, x + y = 1
# Solution: x = y = 1/2, Î» = -1
```

### 3.4.2 Contraintes Convexes

Pour f convexe et contraintes convexes g(x) â‰¤ 0, les conditions KKT sont :

```
âˆ‡f(x*) + Î£áµ¢ Î»áµ¢* âˆ‡gáµ¢(x*) = 0
gáµ¢(x*) â‰¤ 0
Î»áµ¢* â‰¥ 0
Î»áµ¢* gáµ¢(x*) = 0  (complÃ©mentaritÃ©)
```

**PropriÃ©tÃ©** : Si (x*, Î»*) satisfait KKT, alors x* est optimal.

### 3.4.3 Applications

#### SVM (Support Vector Machine)

ProblÃ¨me primal :
```
minimize    (1/2)â€–wâ€–Â²
subject to  yáµ¢(wáµ€xáµ¢ + b) â‰¥ 1  pour i = 1, ..., n
```

ProblÃ¨me dual :
```
maximize    Î£áµ¢ Î±áµ¢ - (1/2)Î£áµ¢â±¼ Î±áµ¢Î±â±¼yáµ¢yâ±¼(xáµ¢áµ€xâ±¼)
subject to  0 â‰¤ Î±áµ¢  et  Î£áµ¢ Î±áµ¢yáµ¢ = 0
```

### 3.4.4 Descente de Gradient ProjetÃ©e

Pour minimiser f(x) avec x âˆˆ C :

```
x_{k+1} = P_C(x_k - Î±_k âˆ‡f(x_k))
```

oÃ¹ P_C est la projection sur C.

**Projection sur simplexe** (Î£áµ¢ xáµ¢ = 1, xáµ¢ â‰¥ 0) :
```python
def project_simplex(v):
    """
    Projette v sur le simplexe
    """
    n = len(v)
    u = np.sort(v)[::-1]
    cssv = np.cumsum(u)
    rho = np.nonzero(u * np.arange(1, n+1) > (cssv - 1))[0][-1]
    theta = (cssv[rho] - 1) / (rho + 1)
    return np.maximum(v - theta, 0)
```

---

## 3.5 ProblÃ¨mes Convexes GÃ©nÃ©raux

### 3.5.1 Ã‰pigraphes

L'**Ã©pigraphe** de f est :
```
epi(f) = {(x, t) : f(x) â‰¤ t}
```

**PropriÃ©tÃ©** : f est convexe âŸº epi(f) est convexe.

### 3.5.2 Sous-Gradients

Pour f convexe (pas nÃ©cessairement diffÃ©rentiable), g est un **sous-gradient** de f en x si :
```
f(y) â‰¥ f(x) + gáµ€(y - x)  pour tout y
```

**Sous-diffÃ©rentiel** :
```
âˆ‚f(x) = {g : g est un sous-gradient de f en x}
```

**Exemples** :
- f(x) = |x| : âˆ‚f(0) = [-1, 1]
- f(x) = max(x, 0) : âˆ‚f(0) = [0, 1]

### 3.5.3 DÃ©rivÃ©es Directionnelles

La **dÃ©rivÃ©e directionnelle** de f en x dans la direction v est :
```
f'(x; v) = lim_{tâ†’0âº} [f(x + tv) - f(x)] / t
```

Pour f convexe :
```
f'(x; v) = max{gáµ€v : g âˆˆ âˆ‚f(x)}
```

### 3.5.4 Descente de Sous-Gradient

Pour f convexe non diffÃ©rentiable :

```
x_{k+1} = x_k - Î±_k g_k  oÃ¹ g_k âˆˆ âˆ‚f(x_k)
```

**Note** : La convergence est plus lente que la descente de gradient (taux en O(1/âˆšk)).

### 3.5.5 MÃ©thodes Proximales

L'**opÃ©rateur proximal** de f est :
```
prox_f(v) = argmin_x {f(x) + (1/2)â€–x - vâ€–Â²}
```

**Algorithme du Gradient Proximal** :
Pour minimiser f(x) + g(x) oÃ¹ f est lisse et g convexe :

```
x_{k+1} = prox_{Î±_k g}(x_k - Î±_k âˆ‡f(x_k))
```

**Exemple : Lasso** (f(x) = â€–Ax - bâ€–Â², g(x) = Î»â€–xâ€–â‚)

```python
def soft_threshold(x, threshold):
    """
    OpÃ©rateur proximal de â€–Â·â€–â‚
    """
    return np.sign(x) * np.maximum(np.abs(x) - threshold, 0)

def lasso_proximal_gradient(A, b, lambda_param, alpha=0.01, max_iter=1000):
    """
    ISTA pour Lasso
    """
    n = A.shape[1]
    x = np.zeros(n)
    
    for k in range(max_iter):
        # Gradient de f
        grad = A.T @ (A @ x - b)
        
        # Ã‰tape de gradient
        z = x - alpha * grad
        
        # Ã‰tape proximale
        x = soft_threshold(z, alpha * lambda_param)
    
    return x
```

---

## 3.6 DualitÃ©

### 3.6.1 Conditions KKT GÃ©nÃ©ralisÃ©es

Pour le problÃ¨me :
```
minimize    f(x)
subject to  g(x) â‰¤ 0, h(x) = 0
```

**Lagrangien** :
```
â„’(x, Î», Î½) = f(x) + Î»áµ€g(x) + Î½áµ€h(x)
```

### 3.6.2 ProblÃ¨me Dual

**Fonction duale** :
```
q(Î», Î½) = inf_x â„’(x, Î», Î½)
```

**ProblÃ¨me dual** :
```
maximize    q(Î», Î½)
subject to  Î» â‰¥ 0
```

**DualitÃ© faible** : q(Î», Î½) â‰¤ f(x*) pour tout Î» â‰¥ 0

**DualitÃ© forte** : Sous certaines conditions (Slater), q(Î»*, Î½*) = f(x*)

---

## ğŸ’¡ Points ClÃ©s

1. **ConvexitÃ©** : Simplifie grandement l'optimisation
2. **Gradient** : Direction de descente la plus rapide
3. **SGD** : Essentiel pour les grands datasets
4. **ADAM** : Optimiseur adaptatif trÃ¨s efficace
5. **Proximal** : Pour les fonctions non diffÃ©rentiables
6. **DualitÃ©** : Fournit des bornes et des algorithmes alternatifs

---

[â¬…ï¸ Chapitre prÃ©cÃ©dent](./chapitre-02-analyse-matricielle.md) | [Retour](../README.md) | [Suite â¡ï¸](../partie-2-concepts/chapitre-04-biais-variance.md)

