# Chapitre 20 : Clustering (Regroupement)

## ğŸ“š Introduction

Le clustering consiste Ã  grouper des donnÃ©es similaires sans labels supervisÃ©s.

## ğŸ—ºï¸ Carte Mentale : MÃ©thodes de Clustering

```
                        CLUSTERING
                            â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                   â”‚                   â”‚
    PARTITIONNEMENT    HIÃ‰RARCHIQUE         DENSITÃ‰
        â”‚                   â”‚                   â”‚
    â”Œâ”€â”€â”€â”´â”€â”€â”€â”           â”Œâ”€â”€â”€â”´â”€â”€â”€â”           â”Œâ”€â”€â”€â”´â”€â”€â”€â”
    â”‚       â”‚           â”‚       â”‚           â”‚       â”‚
 K-means K-medoids  Single  Ward       DBSCAN  HDBSCAN
    â”‚       â”‚      linkage Average        â”‚       â”‚
  Lloyd   PAM      Complete   â”‚        Îµ-voisinage
  K++              â”‚       Dendro       min_samples
                Agglom.
```

## ğŸ“Š Tableau Comparatif : Algorithmes de Clustering

| **MÃ©thode** | **Forme Clusters** | **K requis** | **ScalabilitÃ©** | **Outliers** | **ComplexitÃ©** | **Usage** |
|------------|-------------------|-------------|----------------|-------------|---------------|-----------|
| **K-means** | SphÃ©riques | âœ“ Oui | âœ“âœ“âœ“ Excellente | âœ— Sensible | O(nKi) | Standard, Big Data |
| **HiÃ©rarchique** | Arbitraire | âœ— Non | âš ï¸ Faible | âœ“ Robuste | O(nÂ³) | Petits datasets |
| **Spectral** | Non-convexe | âœ“ Oui | âš ï¸ Moyenne | âœ“ Robuste | O(nÂ³) | Formes complexes |
| **DBSCAN** | Arbitraire | âœ— Non | âœ“âœ“ Bonne | âœ“âœ“ TrÃ¨s robuste | O(n log n) | DensitÃ© variable |
| **GMM** | Elliptiques | âœ“ Oui | âœ“âœ“ Bonne | âš ï¸ Sensible | O(nKÂ²i) | Probabiliste |

## ğŸ“ Visualisation : Comparaison des MÃ©thodes

```
Dataset Exemple :          K-means :           Spectral :         DBSCAN :

   â—â—â—  â—‹â—‹â—‹                â—â—â—  â—‹â—‹â—‹            â—â—â—  â—‹â—‹â—‹          â—â—â—  â—‹â—‹â—‹
  â—â—â—   â—‹â—‹                â—â—â—   â—‹â—‹            â—â—â—   â—‹â—‹          â—â—â—   â—‹â—‹
   â—     â—‹                 â—     â—‹              â—     â—‹            â—     â—‹
    â—   â—‹                   â—   â—‹               â—   â—‹             â—   â—‹
  â—â—â—â— â—‹â—‹â—‹â—‹              â—â—â—â— â—‹â—‹â—‹â—‹           â—â—â—â— â—‹â—‹â—‹â—‹         â—â—â—â— â—‹â—‹â—‹â—‹
  â—â—â—â— â—‹â—‹â—‹â—‹              â—â—â—â— â—‹â—‹â—‹â—‹           â—â—â—â— â—‹â—‹â—‹â—‹         â—â—â—â— â—‹â—‹â—‹â—‹

RÃ©sultat :              âœ“ SphÃ©riques        âœ“ Non-convexes     âœ“ Forme + DensitÃ©
                        âœ— Forme fixe        âœ“ Flexible         âœ“ Outliers dÃ©tectÃ©s
```

## ğŸ¯ K-means : Algorithme DÃ©taillÃ©

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  ALGORITHME K-MEANS                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

INITIALISATION (K-means++) :
  1. Choisir 1er centre Î¼â‚ au hasard
  2. Pour k = 2 to K :
     Choisir Î¼â‚– avec P(x) âˆ D(x)Â² 
     (oÃ¹ D(x) = distance au centre le plus proche)

ITÃ‰RATION :
  Ã‰tape 1 : ASSIGNMENT
    Pour chaque point xáµ¢ :
      cáµ¢ = argmin_k â€–xáµ¢ - Î¼â‚–â€–Â²
      
    Visualisation :
         Î¼â‚â—              Î¼â‚‚â—
        â•±  â”‚  â•²          â•±  â”‚  â•²
       â—   â—   â—        â—   â—   â—
      Cluster 1        Cluster 2

  Ã‰tape 2 : UPDATE
    Pour chaque cluster k :
      Î¼â‚– = (1/|Câ‚–|) Î£_{i:cáµ¢=k} xáµ¢
      
    Nouveaux centres = barycentres

CONVERGENCE :
  â€¢ Objectif minimisÃ© : Î£áµ¢ â€–xáµ¢ - Î¼_{cáµ¢}â€–Â²
  â€¢ Garantie : Objectif dÃ©croÃ®t Ã  chaque itÃ©ration
  â€¢ ArrÃªt : Centres ne bougent plus (ou max iter)
```

---

## 20.1 Introduction

**Objectif** : Partitionner n observations en K groupes.

---

## 20.2 Clustering HiÃ©rarchique

### 20.2.1 Dendrogrammes

**Bottom-up** : Fusionner progressivement les clusters les plus proches.

### 20.2.2 MÃ©triques de Liaison

**Single linkage** : min_{xâˆˆCâ‚,yâˆˆCâ‚‚} d(x, y)
**Complete linkage** : max_{xâˆˆCâ‚,yâˆˆCâ‚‚} d(x, y)
**Average linkage** : moyenne des distances

```python
from scipy.cluster.hierarchy import dendrogram, linkage
import matplotlib.pyplot as plt

# Clustering hiÃ©rarchique
Z = linkage(X, method='ward')

# Dendrogramme
plt.figure(figsize=(10, 5))
dendrogram(Z)
plt.show()
```

---

## 20.3 K-means

### Algorithme

1. Initialiser K centres Î¼â‚, ..., Î¼_K
2. **Assignment** : c_i = argmin_k â€–x_i - Î¼_kâ€–Â²
3. **Update** : Î¼_k = mean{x_i : c_i = k}
4. RÃ©pÃ©ter 2-3 jusqu'Ã  convergence

```python
from sklearn.cluster import KMeans

# K-means
kmeans = KMeans(n_clusters=3, random_state=42)
labels = kmeans.fit_predict(X)

# Centres
centers = kmeans.cluster_centers_
```

### K-means++

**Initialisation amÃ©liorÃ©e** : Choisir centres Ã©loignÃ©s.

---

## 20.4 Clustering Spectral

### Principe

1. Construire matrice de similaritÃ© W
2. Calculer Laplacien L = D - W
3. Vecteurs propres de L
4. K-means sur les vecteurs propres

```python
from sklearn.cluster import SpectralClustering

spectral = SpectralClustering(n_clusters=3, affinity='rbf')
labels = spectral.fit_predict(X)
```

---

## 20.5 DBSCAN

**Density-Based** : Trouve clusters de forme arbitraire.

```python
from sklearn.cluster import DBSCAN

dbscan = DBSCAN(eps=0.5, min_samples=5)
labels = dbscan.fit_predict(X)
```

---

## 20.6 Choix du Nombre de Clusters

### MÃ©thode du Coude (Elbow)

Tracer l'inertie vs K.

### Silhouette Score

```
s(i) = (b(i) - a(i)) / max(a(i), b(i))
```

```python
from sklearn.metrics import silhouette_score

scores = []
for k in range(2, 11):
    kmeans = KMeans(n_clusters=k)
    labels = kmeans.fit_predict(X)
    scores.append(silhouette_score(X, labels))
```

---

## 20.7 Clustering BayÃ©sien

**ModÃ¨les de mÃ©lange** : Approche probabiliste.

---

[â¬…ï¸ Partie 5](../partie-5-methodes-generatives/chapitre-19-generatives-profondes.md) | [Retour](../README.md) | [Suite â¡ï¸](./chapitre-21-reduction-dimension.md)

